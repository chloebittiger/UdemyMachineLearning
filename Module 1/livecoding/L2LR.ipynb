{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Implement logistic regression with L2 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](gradient.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_i(1-y_i_hat)-(1-y_i)y_i_hat \n",
    "\n",
    "# y_i-y_i_hat, y_i=1 or 0\n",
    "\n",
    "# the gradient of CE is just (y_i-y_i_hat)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class twoClassLogisticRegression():\n",
    "    def __init__(self, lbda=1., tol=0.001, alpha=0.1):\n",
    "        # __init__ is a function (constructor) called when somebody write \n",
    "        # myModel = twoClassLogisticRegression(lbda=0.5) (1/C)\n",
    "        self.lbda = lbda #regularizer penalty\n",
    "        self.tol = tol #tolerance\n",
    "        self.alpha = alpha #learning rate\n",
    "    \n",
    "    def logistic(self, u):\n",
    "        # u is the linear function of features\n",
    "        # u = w0 + w1*x1 + w2*x2 ... \n",
    "        return 1./(1.+ np.exp(-u)) \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        # model training\n",
    "        # X is the design matrix with the shape N by p\n",
    "        # y is the response as a 1-d array e.g. [0,1,1,0,1...]\n",
    "        N = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        self._class = np.unique(Y) # list all class labels e.g. [\"A\",\"B\"]\n",
    "        assert(len(self._class)==2)\n",
    "        self._class.sort()\n",
    "        self._class = list(self._class)\n",
    "        print \"class labels: \", self._class\n",
    "        Y_label = np.array([self._class.index(y) for y in Y]) # now Y_label is 1 or 0 for sure\n",
    "        Y_label = Y_label[:, np.newaxis] #transform Y_label to be a column vector\n",
    "        \n",
    "        # Y_label is column vector of 0 or 1\n",
    "        \n",
    "        #initialize weights, also use a bias constant, u = w0 + w1x1 + w2x2 ... \n",
    "        w_old = np.random.randn(p,1) # w1...wp, normal distribution\n",
    "        w0_old = np.random.randn(1) # w0, normal distribution\n",
    "    \n",
    "        while(True):\n",
    "            Y_hat = self.logistic(np.dot(X, w_old) + w0_old) #make prediction\n",
    "            g_w = -((Y_label - Y_hat) * X).mean(axis=0)[:,np.newaxis] + self.lbda * w_old \n",
    "            #[:, np.newaxis] to make 1-d vector to 2-d column vector\n",
    "            g_w0 = -(Y_label - Y_hat).mean(axis=0)\n",
    "            # steepest gradient descent\n",
    "            w_new = w_old - self.alpha * g_w\n",
    "            w0_new = w0_old - self.alpha * g_w0\n",
    "            if(((w_old - w_new)**2).sum() < self.tol):\n",
    "                print \"the algorithm has converged\"\n",
    "                break\n",
    "            w_old = w_new\n",
    "            w0_old = w0_new\n",
    "            \n",
    "        self.w = w_new\n",
    "        self.w0 = w0_new\n",
    "        \n",
    "    def predict_prob(self, X):\n",
    "        return self.logistic(np.dot(X, self.w)+ self.w0)\n",
    "\n",
    "    def predict(self,X):\n",
    "        probs = self.predict_prob(X)\n",
    "        labels = [1 if x>0.5 else 0 for x in probs] #using list comprehension, threshold set to be 0.5\n",
    "        return [self._class[label] for label in labels]   \n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        Y_pred = self.predict(X)\n",
    "        accuracy = np.mean(Y == Y_pred)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = twoClassLogisticRegression() # compare to sklearn logisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n",
      "[  1.41272917e+01   1.92896485e+01   9.19690334e+01   6.54889104e+02\n",
      "   9.63602812e-02   1.04340984e-01   8.87993158e-02   4.89191459e-02\n",
      "   1.81161863e-01   6.27976098e-02   4.05172056e-01   1.21685343e+00\n",
      "   2.86605923e+00   4.03370791e+01   7.04097891e-03   2.54781388e-02\n",
      "   3.18937163e-02   1.17961371e-02   2.05422988e-02   3.79490387e-03\n",
      "   1.62691898e+01   2.56772232e+01   1.07261213e+02   8.80583128e+02\n",
      "   1.32368594e-01   2.54265044e-01   2.72188483e-01   1.14606223e-01\n",
      "   2.90075571e-01   8.39458172e-02]\n",
      "[ -3.16286735e-15  -6.53060890e-15  -7.07889127e-16  -8.79983452e-16\n",
      "   6.13217737e-15  -1.12036918e-15  -4.42138027e-16   9.73249991e-16\n",
      "  -1.97167024e-15  -1.45363120e-15  -9.07641468e-16  -8.85349205e-16\n",
      "   1.77367396e-15  -8.29155139e-16  -7.54180940e-16  -3.92187747e-16\n",
      "   7.91789988e-16  -2.73946068e-16  -3.10823423e-16  -3.36676596e-16\n",
      "  -2.33322442e-15   1.76367415e-15  -1.19802625e-15   5.04966114e-16\n",
      "  -5.21317026e-15  -2.17478837e-15   6.85645643e-16  -1.41265636e-16\n",
      "  -2.28956670e-15   2.57517109e-15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(X.mean(axis=0)) # compute every feature's mean\n",
    "\n",
    "\n",
    "# preprocessing standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X) # standardization\n",
    "print(X.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels:  [0, 1]\n",
      "the algorithm has converged\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92442882249560632"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, Y) #training accuracy"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
